{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dJuZDx9qWeM"
   },
   "source": [
    "# 1.) Import an asset price from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3bcwJb4rp93",
    "outputId": "6488930e-f8a4-4ecb-a3ce-cc73d755672d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 10:13:10.721418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "\n",
    "########################################\n",
    "####Pick your ticker and time period####\n",
    "########################################\n",
    "stock_data = yf.download(\"^GSPC\", start=\"1990-01-01\", end=\"2022-02-21\")\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "scaled_data = np.array(stock_data[\"Close\"].pct_change().dropna()).reshape(-1,1)\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "training_data_len = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[0:training_data_len, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foHoGy9hq3_o"
   },
   "source": [
    "# 2.) Create your x_train/y_train data so that your RNN uses percentage change data to make a binary forecast where the stock moves up or down the next day\n",
    "# Build an RNN Architecture accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qGFB5HfqcVd"
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "#############################################################\n",
    "####Pick your input size and edit to make binary forecast####\n",
    "#############################################################\n",
    "input_size = []\n",
    "for i in range(input_size, len(train_data)):\n",
    "    x_train.append(train_data[i-input_size:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "###################################\n",
    "####Build Your RNN Architecture####\n",
    "###################################\n",
    "model = Sequential()\n",
    "model.add(LSTM(x_train.shape[1], return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "#Examples\n",
    "#model.add(LSTM(50, return_sequences=False))\n",
    "#model.add(Dense(25))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p3BlSFA8Na77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFhO9vMjsWPk"
   },
   "source": [
    "# 3.) Test your model and compare insample Accurracy, insample random walk assumption Accuracy, Out of sample Accuracy and out of sample random walk assumption Accuracy using a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r1Xj6Ji-rwnM"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data = scaled_data[training_data_len - input_size:, :]\n",
    "\n",
    "x_test = []\n",
    "y_test = np.array(stock_data[[\"Close\"]].pct_change().dropna())[training_data_len:, :]\n",
    "for i in range(input_size, len(test_data)):\n",
    "    x_test.append(test_data[i-input_size:i, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Mvo2INihZMhk"
   },
   "outputs": [],
   "source": [
    "# oos random walk\n",
    "y_test[1:] #actual\n",
    "y_test[:-1] #prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "35O_7b3iX1cX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZP_GJ8X-Wkln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jVPe8djTn1_2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QCY8DfMEtUln"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK_jyyEEtTUB"
   },
   "source": [
    "#5.) Write an observation/conclusion about the graphs from Q4 and Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FlD_yx0cshJ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N5fbjajz-YCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKaNjoQlBPbr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFtrp-lmtw6t"
   },
   "source": [
    "# 6.) Create a parameter for number of lags in your input layer. Do a 3-fold CV to test three different time lags. i.e. Tested using 5,10,20 days of previous price data to forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEOQ6TO0-Fnw",
    "outputId": "2f87315c-c4c1-404c-ab40-3654f0c73582"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-f5508c983bfa>:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.000000 using {'batch_size': 10, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Define the Keras model\n",
    "###Edit here to create your optimizer\n",
    "def create_model(): #add a parameter that will change number of inputs\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=60, activation='LSTM'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "# Wrap the Keras model in a scikit-learn compatible estimator\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "####EXAMPLE###\n",
    "#param_grid = {'batch_size': [10, 20, 100],\n",
    "#              'epochs': [10, 100],\n",
    "#              'neurons':[5,10,20]}\n",
    "\n",
    "# Perform the grid search over the hyperparameters\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA_gAupmA_8E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfH6js5EB2wu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
